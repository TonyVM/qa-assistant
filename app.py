import streamlit as st
from pdf_reader import extract_text_from_pdf
from generator import generate_test_artifacts, get_available_models
from utils import save_to_csv

st.set_page_config(page_title="QA Assistant v1.2.0-beta", layout="centered")
st.title("üßµ QA Test Case Assistant")
st.caption("Version 1.2.0-beta - Multi-Model + Gherkin BDD Support")

# Sidebar para configuraciones del modelo
with st.sidebar:
    st.header("ü§ñ Model Configuration")

    # Selecci√≥n del proveedor
    model_provider = st.selectbox(
        "Select AI Provider:",
        ["openai", "gemini"],
        help="Choose between OpenAI or Google Gemini models",
    )

    # Obtener modelos disponibles
    available_models = get_available_models()

    # Selecci√≥n del modelo espec√≠fico
    model_name = st.selectbox(
        f"Select {model_provider.upper()} Model:",
        available_models[model_provider],
        help=f"Choose the specific {model_provider} model to use",
    )

    st.markdown("---")

    # Secci√≥n de API Keys
    st.subheader("üîë API Key Configuration")

    # Campo para ingresar API key seg√∫n el proveedor seleccionado
    if model_provider == "openai":
        api_key = st.text_input(
            "OpenAI API Key:",
            type="password",
            placeholder="sk-...",
            help="Enter your OpenAI API key here",
        )

        # Tutorial para OpenAI
        with st.expander("üìö How to get OpenAI API Key"):
            st.markdown(
                """
            **Step 1:** Go to [OpenAI Platform](https://platform.openai.com/)
            
            **Step 2:** Click on the settings icon (‚öôÔ∏è) in the top right corner
            
            **Step 3:** In the left sidebar menu, click on "API keys"
            
            **Step 4:** Click the "Create new secret key" button
            
            **Step 5:** Copy your API key and paste it in the field above
            
            ‚ö†Ô∏è **Important:** Keep your API key secure and don't share it!
            """
            )

    else:  # gemini
        api_key = st.text_input(
            "Google API Key:",
            type="password",
            placeholder="AIza...",
            help="Enter your Google API key here",
        )

        # Tutorial para Gemini
        with st.expander("üìö How to get Google Gemini API Key"):
            st.markdown(
                """
            **Step 1:** Go to [Google AI Studio](https://aistudio.google.com/app/apikey)
            
            **Step 2:** Click the "Create API key" button
            
            **Step 3:** Select your Google Cloud project or create a new one
            
            **Step 4:** Copy your API key and paste it in the field above
            
            ‚ö†Ô∏è **Important:** Keep your API key secure and don't share it!
            """
            )

    # Validaci√≥n de API key
    if api_key:
        if model_provider == "openai" and api_key.startswith("sk-"):
            st.success("‚úÖ OpenAI API key format looks correct")
        elif model_provider == "gemini" and api_key.startswith("AIza"):
            st.success("‚úÖ Google API key format looks correct")
        else:
            st.warning("‚ö†Ô∏è API key format may be incorrect")
    else:
        st.info(f"üí° Enter your {model_provider.upper()} API key to get started")

# Main interface
uploaded_file = st.file_uploader("Upload a requirements document (PDF)", type=["pdf"])

if uploaded_file:
    text = extract_text_from_pdf(uploaded_file)
    st.success("Document processed successfully!")

    # Mostrar informaci√≥n del documento
    with st.expander("üìÑ Document Information"):
        st.write(f"**Document name:** {uploaded_file.name}")
        st.write(f"**Text length:** {len(text):,} characters")

        # Calcular l√≠mite din√°mico basado en el modelo seleccionado
        model_limits = {
            "gpt-3.5-turbo": 12000,
            "gpt-4": 24000,
            "gpt-4-turbo-preview": 100000,
            "gemini-pro": 20000,
            "gemini-pro-vision": 20000,
        }

        max_chars = model_limits.get(model_name, 12000)

        if len(text) > max_chars:
            st.warning(
                f"‚ö†Ô∏è Document is large ({len(text):,} characters). "
                f"The model {model_name} can process up to {max_chars:,} characters. "
                f"The text will be intelligently truncated to preserve complete paragraphs."
            )
        else:
            st.info(
                f"‚úÖ Document size is optimal for {model_name} "
                f"({len(text):,}/{max_chars:,} characters)"
            )

    action = st.radio(
        "What do you want to generate?",
        ["User Stories", "Gherkin User Stories", "Test Scenarios", "Test Cases"],
        help="Select the type of testing artifact to generate",
    )

    if st.button("üöÄ Generate", type="primary"):
        if not api_key:
            st.error(
                f"‚ö†Ô∏è Please enter your {model_provider.upper()} API key to continue"
            )
        else:
            with st.spinner(
                f"Generating with {model_provider.upper()} {model_name}..."
            ):
                try:
                    results = generate_test_artifacts(
                        text, action, model_provider, model_name, api_key
                    )

                    if results.startswith("Error"):
                        st.error(results)
                    else:
                        st.success("Generation completed!")
                        st.text_area(
                            "Generated Output",
                            results,
                            height=300,
                            help="Review the generated content before downloading",
                        )

                        csv_path = save_to_csv(results, action)

                        # Botones de descarga y nueva generaci√≥n
                        col1, col2 = st.columns(2)
                        with col1:
                            st.download_button(
                                "üì• Download as CSV",
                                open(csv_path, "rb"),
                                file_name=f"{action.replace(' ', '_').lower()}.csv",
                                type="primary",
                            )
                        with col2:
                            if st.button("üîÑ Generate Again"):
                                st.rerun()

                except Exception as e:
                    st.error(f"An error occurred: {str(e)}")
                    st.info("Please check your API key and internet connection.")

# Footer with information
st.markdown("---")

# Secci√≥n de ayuda
with st.expander("‚ùì Need Help?"):
    st.markdown(
        """
    ### üöÄ Getting Started
    
    1. **Choose your AI provider** (OpenAI or Google Gemini) in the sidebar
    2. **Select a model** that fits your document size
    3. **Enter your API key** using the tutorial links in the sidebar
    4. **Upload a PDF** with your requirements
    5. **Select the artifact type** you want to generate
    6. **Click Generate** and wait for the results
    
    ### ÔøΩ Available Artifact Types
    
    - **User Stories**: Traditional user stories in "As a... I want... So that..." format
    - **Gherkin User Stories**: BDD-style user stories with Given/When/Then scenarios
    - **Test Scenarios**: High-level test scenarios covering different cases
    - **Test Cases**: Detailed test cases with steps and expected results
    
    ### ü•í What is Gherkin?
    
    Gherkin is a business-readable language for BDD (Behavior Driven Development):
    - **Feature**: Describes the software feature
    - **Scenario**: Specific test case
    - **Given**: Initial context/preconditions
    - **When**: Action or event
    - **Then**: Expected outcome
    
    Perfect for teams using Cucumber, Behave, or SpecFlow!
    
    ### ÔøΩüìè Document Size Guidelines
    
    - **Small documents** (< 12K chars): Use GPT-3.5-turbo or Gemini-pro
    - **Medium documents** (12K-24K chars): Use GPT-4 or Gemini-pro
    - **Large documents** (24K-100K chars): Use GPT-4-turbo-preview
    
    ### üîí Security Note
    
    Your API keys are only used during the session and are not stored or logged.
    """
    )

st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        üßµ QA Test Case Assistant | Powered by LangChain<br>
        Supports OpenAI GPT and Google Gemini models
    </div>
    """,
    unsafe_allow_html=True,
)
